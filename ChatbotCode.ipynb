{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install -qU \\\n",
    "    langchain==0.0.354 \\\n",
    "    openai==1.6.1 \\\n",
    "    datasets==2.10.1 \\\n",
    "    pinecone-client==3.1.0 \\\n",
    "    tiktoken==0.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \"YOUR_API_KEY\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
    "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
    "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/66/k5gz0n6n7v30520l2h2dln600000gp/T/ipykernel_87075/640822517.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mchat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessages\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mres\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/_api/deprecation.py\u001B[0m in \u001B[0;36mwarning_emitting_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    143\u001B[0m                 \u001B[0mwarned\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m                 \u001B[0memit_warning\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m         \u001B[0;32masync\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mawarning_emitting_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, messages, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    689\u001B[0m         \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    690\u001B[0m     ) -> BaseMessage:\n\u001B[0;32m--> 691\u001B[0;31m         generation = self.generate(\n\u001B[0m\u001B[1;32m    692\u001B[0m             \u001B[0;34m[\u001B[0m\u001B[0mmessages\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    693\u001B[0m         ).generations[0][0]\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001B[0m\n\u001B[1;32m    406\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mrun_managers\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    407\u001B[0m                     \u001B[0mrun_managers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_llm_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mLLMResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 408\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    409\u001B[0m         flattened_outputs = [\n\u001B[1;32m    410\u001B[0m             \u001B[0mLLMResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerations\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerations\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mllm_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mllm_output\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001B[0m\n\u001B[1;32m    396\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    397\u001B[0m                 results.append(\n\u001B[0;32m--> 398\u001B[0;31m                     self._generate_with_cache(\n\u001B[0m\u001B[1;32m    399\u001B[0m                         \u001B[0mm\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    400\u001B[0m                         \u001B[0mstop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstop\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/language_models/chat_models.py\u001B[0m in \u001B[0;36m_generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    575\u001B[0m                 )\n\u001B[1;32m    576\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mnew_arg_supported\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 577\u001B[0;31m                 return self._generate(\n\u001B[0m\u001B[1;32m    578\u001B[0m                     \u001B[0mmessages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrun_manager\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrun_manager\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    579\u001B[0m                 )\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_community/chat_models/openai.py\u001B[0m in \u001B[0;36m_generate\u001B[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001B[0m\n\u001B[1;32m    437\u001B[0m             \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    438\u001B[0m         }\n\u001B[0;32m--> 439\u001B[0;31m         response = self.completion_with_retry(\n\u001B[0m\u001B[1;32m    440\u001B[0m             \u001B[0mmessages\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmessage_dicts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrun_manager\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrun_manager\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    441\u001B[0m         )\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_community/chat_models/openai.py\u001B[0m in \u001B[0;36mcompletion_with_retry\u001B[0;34m(self, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    354\u001B[0m         \u001B[0;34m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    355\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mis_openai_v1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 356\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    357\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    358\u001B[0m         \u001B[0mretry_decorator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_create_retry_decorator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrun_manager\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrun_manager\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/_utils/_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    270\u001B[0m                         \u001B[0mmsg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    271\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 272\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    273\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    274\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/resources/chat/completions.py\u001B[0m in \u001B[0;36mcreate\u001B[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    643\u001B[0m         \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfloat\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0mhttpx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTimeout\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0mNotGiven\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mNOT_GIVEN\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    644\u001B[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001B[0;32m--> 645\u001B[0;31m         return self._post(\n\u001B[0m\u001B[1;32m    646\u001B[0m             \u001B[0;34m\"/chat/completions\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    647\u001B[0m             body=maybe_transform(\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001B[0m in \u001B[0;36mpost\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1086\u001B[0m             \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"post\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mjson_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbody\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiles\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mto_httpx_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiles\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1087\u001B[0m         )\n\u001B[0;32m-> 1088\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mResponseT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcast_to\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstream_cls\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstream_cls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1089\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1090\u001B[0m     def patch(\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    851\u001B[0m         \u001B[0mstream_cls\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtype\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0m_StreamT\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m|\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    852\u001B[0m     ) -> ResponseT | _StreamT:\n\u001B[0;32m--> 853\u001B[0;31m         return self._request(\n\u001B[0m\u001B[1;32m    854\u001B[0m             \u001B[0mcast_to\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcast_to\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    855\u001B[0m             \u001B[0moptions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/openai/_base_client.py\u001B[0m in \u001B[0;36m_request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    928\u001B[0m                 \u001B[0merr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    929\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 930\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_status_error_from_response\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    931\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m         return self._process_response(\n",
      "\u001B[0;31mAuthenticationError\u001B[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_API_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
     ]
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "OPENAI_API_KEY="
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
